{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# !pip install autokeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "import autokeras as ak\n",
    "\n",
    "import plotly.express as px\n",
    "import copy \n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.datasets import make_classification\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_roc(y, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "\n",
    "    fig = px.area(\n",
    "        x=fpr, y=tpr,\n",
    "        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "        labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.show()\n",
    "    \n",
    "def plot_pr_curve(y, y_score):    \n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_score)\n",
    "\n",
    "    fig = px.area(\n",
    "        x=recall, y=precision,\n",
    "        title=f'Precision-Recall Curve (AUC={auc(recall, precision):.4f})',\n",
    "        labels=dict(x='Recall', y='Precision'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0\n",
    "    )\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.show()    \n",
    "    \n",
    "def plot_roc_train_test(y_train, y_score_train, y_test, y_score_test):\n",
    "    fig = go.Figure()\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{Y_Names[i]} ROC (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def plot_pr_train_test(y_train, y_score_train, y_test, y_score_test):\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    \n",
    "    # subplot for ROC curve\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{Y_Names[i]} ROC (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'),row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"True Positive Rate\", row=1, col=1)\n",
    "    \n",
    "    # subplot for PR curve\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0, \n",
    "        row=1,col=2\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_score = average_precision_score(y_true, y_score)\n",
    "    \n",
    "        name = f\"{Y_Names[i]} PR (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=recall, y=precision, name=name, mode='lines'),row=1,col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Recall\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Precision\", row=1, col=2)\n",
    "    fig.update_layout(\n",
    "        title=\"ROC & Precision-Recall Curves\",\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=1000, height=500\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def hyper_table(path='structured_data_classifier'):\n",
    "    trial_json = os.popen('ls ./{}/trial_*/trial.json'.format(path)).read().split('\\n')[:-1]\n",
    "    DATA = []\n",
    "    for file in trial_json:\n",
    "        with open(file) as f: \n",
    "            DATA.append(json.load(f))\n",
    "    for k in range(len(DATA)):\n",
    "        DATA[k]['hyperparameters']['values']['score'] = DATA[k]['score']\n",
    "    hyper_df = pd.concat([pd.DataFrame.from_dict(data['hyperparameters']['values'], orient='index') for data in DATA], axis=1)\n",
    "    hyper_df.columns = [\"trial#{}\".format(k+1) for k in range(len(DATA))]\n",
    "    return(hyper_df)\n",
    "\n",
    "def predic_error_analysis(x_train, y_train, y_score_train, x_test, y_test, y_score):\n",
    "    df1 = copy.deepcopy(pd.DataFrame(x_train))\n",
    "    df1['obs'] = pd.DataFrame(y_train)\n",
    "    df1['predict'] = pd.DataFrame(y_score_train)\n",
    "    df1['data'] = 'Train'\n",
    "    #display(df1)\n",
    "    df2 = copy.deepcopy(pd.DataFrame(x_test))\n",
    "    df2['obs'] = pd.DataFrame(y_test)\n",
    "    df2['predict'] = pd.DataFrame(y_score)\n",
    "    df2['data'] = 'Test'\n",
    "    #display(df2)\n",
    "    df3 = pd.concat([df1,df2])\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df3, x='obs', y='predict',\n",
    "        marginal_x='histogram', marginal_y='histogram',\n",
    "        color='data', trendline='ols'\n",
    "    )\n",
    "    fig.update_traces(histnorm='probability', selector={'type':'histogram'})\n",
    "    fig.add_shape(\n",
    "        type=\"line\", line=dict(dash='dash'),\n",
    "        x0=df3['obs'].min(), y0=df3['obs'].min(),\n",
    "        x1=df3['obs'].max(), y1=df3['obs'].max()\n",
    "    )\n",
    "    fig.update_layout(title=\"Prediction Error Analysis\", \n",
    "                      yaxis=dict(range=[df3['obs'].min(), df3['obs'].max()]),\n",
    "                      xaxis=dict(range=[df3['obs'].min(), df3['obs'].max()]),\n",
    "                      width=1000, height=1000)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To make this tutorial easy to follow, we just treat IMDB dataset as a\n",
    "regression dataset. It means we will treat prediction targets of IMDB dataset,\n",
    "which are 0s and 1s as numerical values, so that they can be directly used as\n",
    "the regression targets.\n",
    "\n",
    "## A Simple Example\n",
    "The first step is to prepare your data. Here we use the [IMDB\n",
    "dataset](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification)\n",
    "as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "b'Zero Day leads you to think, even re-think why two'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\",\n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "# set path to dataset\n",
    "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "classes = [\"pos\", \"neg\"]\n",
    "train_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
    ")\n",
    "test_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
    ")\n",
    "\n",
    "x_train = np.array(train_data.data)\n",
    "y_train = np.array(train_data.target)\n",
    "x_test = np.array(test_data.data)\n",
    "y_test = np.array(test_data.target)\n",
    "\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # <START> this film was just brilliant casting <UNK>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The second step is to run the [TextRegressor](/text_regressor).  As a quick\n",
    "demo, we set epochs to 2.  You can also leave the epochs unspecified for an\n",
    "adaptive number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"Zero Day leads you to think, even re-think w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Words can\\'t describe how bad this movie is....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Everyone plays their part pretty well in thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'There are a lot of highly talented filmmaker...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'I\\'ve just had the evidence that confirmed m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>b'089: Footlight Parade (1933) - released 9/30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>b'Deeply humorous yet honest comedy about a bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>b'1st watched 2/28/2006 - 4 out of 10(Dir-Sydn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>b\"I watch lots of scary movies (or at least th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>b'Absolutely the worst film yet by Burton, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  target\n",
       "0      b\"Zero Day leads you to think, even re-think w...       1\n",
       "1      b'Words can\\'t describe how bad this movie is....       0\n",
       "2      b'Everyone plays their part pretty well in thi...       1\n",
       "3      b'There are a lot of highly talented filmmaker...       0\n",
       "4      b'I\\'ve just had the evidence that confirmed m...       0\n",
       "...                                                  ...     ...\n",
       "24995  b'089: Footlight Parade (1933) - released 9/30...       1\n",
       "24996  b'Deeply humorous yet honest comedy about a bu...       1\n",
       "24997  b'1st watched 2/28/2006 - 4 out of 10(Dir-Sydn...       0\n",
       "24998  b\"I watch lots of scary movies (or at least th...       0\n",
       "24999  b'Absolutely the worst film yet by Burton, who...       0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(zip(train_data.data, train_data.target), columns = ['data','target'])\n",
    "test_df = pd.DataFrame(zip(test_data.data, test_data.target), columns = ['data','target'])\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 15s]\n",
      "val_loss: 0.16080547869205475\n",
      "\n",
      "Best val_loss So Far: 0.16080547869205475\n",
      "Total elapsed time: 00h 00m 15s\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2443 - mean_squared_error: 0.2443\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1454 - mean_squared_error: 0.1454\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1565 - mean_squared_error: 0.1565\n",
      "[0.15651313960552216, 0.15651313960552216]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial#1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_block_1/block_type</th>\n",
       "      <td>vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/max_tokens</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/text_to_int_sequence_1/output_sequence_length</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/pretraining</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/embedding_dim</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/dropout</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/kernel_size</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/separable</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/max_pooling</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_blocks</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/spatial_reduction_1/reduction_type</th>\n",
       "      <td>global_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/use_batchnorm</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_head_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.160805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       trial#1\n",
       "text_block_1/block_type                                vanilla\n",
       "text_block_1/max_tokens                                   5000\n",
       "text_block_1/text_to_int_sequence_1/output_sequ...          64\n",
       "text_block_1/embedding_1/pretraining                      none\n",
       "text_block_1/embedding_1/embedding_dim                     128\n",
       "text_block_1/embedding_1/dropout                          0.25\n",
       "text_block_1/conv_block_1/kernel_size                        3\n",
       "text_block_1/conv_block_1/separable                      False\n",
       "text_block_1/conv_block_1/max_pooling                     True\n",
       "text_block_1/conv_block_1/dropout                            0\n",
       "text_block_1/conv_block_1/num_blocks                         2\n",
       "text_block_1/conv_block_1/num_layers                         2\n",
       "text_block_1/conv_block_1/filters_0_0                       32\n",
       "text_block_1/conv_block_1/filters_0_1                       32\n",
       "text_block_1/conv_block_1/filters_1_0                       32\n",
       "text_block_1/conv_block_1/filters_1_1                       32\n",
       "text_block_1/spatial_reduction_1/reduction_type     global_max\n",
       "text_block_1/dense_block_1/use_batchnorm                 False\n",
       "text_block_1/dense_block_1/num_layers                        2\n",
       "text_block_1/dense_block_1/units_0                          32\n",
       "text_block_1/dense_block_1/dropout                           0\n",
       "text_block_1/dense_block_1/units_1                          32\n",
       "regression_head_1/dropout                                    0\n",
       "optimizer                                                 adam\n",
       "learning_rate                                            0.001\n",
       "score                                                 0.160805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 64, 128)           640128    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 62, 32)            12320     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 60, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 28, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 26, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 663,905\n",
      "Trainable params: 663,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text regressor.\n",
    "reg = ak.TextRegressor(overwrite=True, max_trials=1)  # It tries 10 different models.\n",
    "# Feed the text regressor with training data.\n",
    "reg.fit(x_train, y_train, epochs=2)\n",
    "# Predict with the best model.\n",
    "predicted_y = reg.predict(x_test)\n",
    "# Evaluate the best model with testing data.\n",
    "print(reg.evaluate(x_test, y_test))\n",
    "\n",
    "# structure of the model\n",
    "display(hyper_table(path='text_regressor'))\n",
    "model = reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Validation Data\n",
    "By default, AutoKeras use the last 20% of training data as validation data.  As\n",
    "shown in the example below, you can use `validation_split` to specify the\n",
    "percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "reg.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You can also use your own validation set instead of splitting it from the\n",
    "training data with `validation_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "split = 5000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "reg.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Customized Search Space\n",
    "For advanced users, you may customize your search space by using\n",
    "[AutoModel](/auto_model/#automodel-class) instead of\n",
    "[TextRegressor](/text_regressor). You can configure the\n",
    "[TextBlock](/block/#textblock-class) for some high-level configurations, e.g.,\n",
    "`vectorizer` for the type of text vectorization method to use.  You can use\n",
    "'sequence', which uses [TextToInteSequence](/block/#texttointsequence-class) to\n",
    "convert the words to integers and use [Embedding](/block/#embedding-class) for\n",
    "embedding the integer sequences, or you can use 'ngram', which uses\n",
    "[TextToNgramVector](/block/#texttongramvector-class) to vectorize the\n",
    "sentences.  You can also do not specify these arguments, which would leave the\n",
    "different choices to be tuned automatically.  See the following example for\n",
    "detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 21s]\n",
      "val_loss: 0.20535746216773987\n",
      "\n",
      "Best val_loss So Far: 0.20535746216773987\n",
      "Total elapsed time: 00h 00m 21s\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 9s 56ms/step - loss: 1.8342 - mean_squared_error: 1.8342\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 9s 56ms/step - loss: 0.5069 - mean_squared_error: 0.5069\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial#1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_block_1/block_type</th>\n",
       "      <td>vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/max_tokens</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/text_to_int_sequence_1/output_sequence_length</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/pretraining</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/embedding_dim</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/dropout</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/kernel_size</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/separable</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/max_pooling</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_blocks</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/spatial_reduction_1/reduction_type</th>\n",
       "      <td>global_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/use_batchnorm</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_head_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.160805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       trial#1\n",
       "text_block_1/block_type                                vanilla\n",
       "text_block_1/max_tokens                                   5000\n",
       "text_block_1/text_to_int_sequence_1/output_sequ...          64\n",
       "text_block_1/embedding_1/pretraining                      none\n",
       "text_block_1/embedding_1/embedding_dim                     128\n",
       "text_block_1/embedding_1/dropout                          0.25\n",
       "text_block_1/conv_block_1/kernel_size                        3\n",
       "text_block_1/conv_block_1/separable                      False\n",
       "text_block_1/conv_block_1/max_pooling                     True\n",
       "text_block_1/conv_block_1/dropout                            0\n",
       "text_block_1/conv_block_1/num_blocks                         2\n",
       "text_block_1/conv_block_1/num_layers                         2\n",
       "text_block_1/conv_block_1/filters_0_0                       32\n",
       "text_block_1/conv_block_1/filters_0_1                       32\n",
       "text_block_1/conv_block_1/filters_1_0                       32\n",
       "text_block_1/conv_block_1/filters_1_1                       32\n",
       "text_block_1/spatial_reduction_1/reduction_type     global_max\n",
       "text_block_1/dense_block_1/use_batchnorm                 False\n",
       "text_block_1/dense_block_1/num_layers                        2\n",
       "text_block_1/dense_block_1/units_0                          32\n",
       "text_block_1/dense_block_1/dropout                           0\n",
       "text_block_1/dense_block_1/units_1                          32\n",
       "regression_head_1/dropout                                    0\n",
       "optimizer                                                 adam\n",
       "learning_rate                                            0.001\n",
       "score                                                 0.160805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1280256   \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,293,513\n",
      "Trainable params: 1,288,513\n",
      "Non-trainable params: 5,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "reg = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "reg.fit(x_train, y_train, epochs=2)\n",
    "\n",
    "# structure of the model\n",
    "display(hyper_table(path='text_regressor'))\n",
    "model = reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The usage of [AutoModel](/auto_model/#automodel-class) is similar to the\n",
    "[functional API](https://www.tensorflow.org/guide/keras/functional) of Keras.\n",
    "Basically, you are building a graph, whose edges are blocks and the nodes are\n",
    "intermediate outputs of blocks.  To add an edge from `input_node` to\n",
    "`output_node` with `output_node = ak.[some_block]([block_args])(input_node)`.\n",
    "\n",
    "You can even also use more fine grained blocks to customize the search space\n",
    "even further. See the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 05s]\n",
      "val_loss: 0.24539391696453094\n",
      "\n",
      "Best val_loss So Far: 0.24539391696453094\n",
      "Total elapsed time: 00h 00m 05s\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 3s 14ms/step - loss: 0.3522 - mean_squared_error: 0.3522\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.2512 - mean_squared_error: 0.2512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial#1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_block_1/block_type</th>\n",
       "      <td>vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/max_tokens</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/text_to_int_sequence_1/output_sequence_length</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/pretraining</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/embedding_dim</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/dropout</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/kernel_size</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/separable</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/max_pooling</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_blocks</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/spatial_reduction_1/reduction_type</th>\n",
       "      <td>global_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/use_batchnorm</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_head_1/dropout</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.160805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       trial#1\n",
       "text_block_1/block_type                                vanilla\n",
       "text_block_1/max_tokens                                   5000\n",
       "text_block_1/text_to_int_sequence_1/output_sequ...          64\n",
       "text_block_1/embedding_1/pretraining                      none\n",
       "text_block_1/embedding_1/embedding_dim                     128\n",
       "text_block_1/embedding_1/dropout                          0.25\n",
       "text_block_1/conv_block_1/kernel_size                        3\n",
       "text_block_1/conv_block_1/separable                      False\n",
       "text_block_1/conv_block_1/max_pooling                     True\n",
       "text_block_1/conv_block_1/dropout                            0\n",
       "text_block_1/conv_block_1/num_blocks                         2\n",
       "text_block_1/conv_block_1/num_layers                         2\n",
       "text_block_1/conv_block_1/filters_0_0                       32\n",
       "text_block_1/conv_block_1/filters_0_1                       32\n",
       "text_block_1/conv_block_1/filters_1_0                       32\n",
       "text_block_1/conv_block_1/filters_1_1                       32\n",
       "text_block_1/spatial_reduction_1/reduction_type     global_max\n",
       "text_block_1/dense_block_1/use_batchnorm                 False\n",
       "text_block_1/dense_block_1/num_layers                        2\n",
       "text_block_1/dense_block_1/units_0                          32\n",
       "text_block_1/dense_block_1/dropout                           0\n",
       "text_block_1/dense_block_1/units_1                          32\n",
       "regression_head_1/dropout                                    0\n",
       "optimizer                                                 adam\n",
       "learning_rate                                            0.001\n",
       "score                                                 0.160805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 64, 128)           2560128   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d (SeparableC (None, 62, 32)            4512      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 60, 32)            1152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_2 (Separabl (None, 28, 32)            1152      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_3 (Separabl (None, 26, 32)            1152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_4 (Separabl (None, 11, 32)            1152      \n",
      "_________________________________________________________________\n",
      "separable_conv1d_5 (Separabl (None, 9, 32)             1152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,570,529\n",
      "Trainable params: 2,570,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextToIntSequence()(input_node)\n",
    "output_node = ak.Embedding()(output_node)\n",
    "# Use separable Conv layers in Keras.\n",
    "output_node = ak.ConvBlock(separable=True)(output_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "reg = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "reg.fit(x_train, y_train, epochs=2)\n",
    "\n",
    "# structure of the model\n",
    "display(hyper_table(path='text_regressor'))\n",
    "model = reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data Format\n",
    "The AutoKeras TextRegressor is quite flexible for the data format.\n",
    "\n",
    "For the text, the input data should be one-dimensional For the regression\n",
    "targets, it should be a vector of numerical values.  AutoKeras accepts\n",
    "numpy.ndarray.\n",
    "\n",
    "We also support using [tf.data.Dataset](\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable)\n",
    "format for the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 04s]\n",
      "val_loss: 0.18503132462501526\n",
      "\n",
      "Best val_loss So Far: 0.17859812080860138\n",
      "Total elapsed time: 00h 00m 08s\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 2s 9ms/step - loss: 0.2933 - mean_squared_error: 0.2933\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.1812 - mean_squared_error: 0.1812\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2185 - mean_squared_error: 0.2185\n",
      "[0.21852049231529236, 0.21852049231529236]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial#1</th>\n",
       "      <th>trial#2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_block_1/block_type</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/max_tokens</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/text_to_int_sequence_1/output_sequence_length</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/pretraining</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/embedding_dim</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/embedding_1/dropout</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/kernel_size</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/separable</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/max_pooling</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_blocks</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_0</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_0_1</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_0</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/conv_block_1/filters_1_1</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/spatial_reduction_1/reduction_type</th>\n",
       "      <td>flatten</td>\n",
       "      <td>flatten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/use_batchnorm</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/num_layers</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_0</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/dropout</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_block_1/dense_block_1/units_1</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_head_1/dropout</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.178598</td>\n",
       "      <td>0.185031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     trial#1   trial#2\n",
       "text_block_1/block_type                              vanilla   vanilla\n",
       "text_block_1/max_tokens                                 5000      5000\n",
       "text_block_1/text_to_int_sequence_1/output_sequ...        64        64\n",
       "text_block_1/embedding_1/pretraining                    none      none\n",
       "text_block_1/embedding_1/embedding_dim                   128       128\n",
       "text_block_1/embedding_1/dropout                        0.25      0.25\n",
       "text_block_1/conv_block_1/kernel_size                      3         3\n",
       "text_block_1/conv_block_1/separable                    False     False\n",
       "text_block_1/conv_block_1/max_pooling                   True      True\n",
       "text_block_1/conv_block_1/dropout                          0       0.5\n",
       "text_block_1/conv_block_1/num_blocks                       2         2\n",
       "text_block_1/conv_block_1/num_layers                       2         2\n",
       "text_block_1/conv_block_1/filters_0_0                     32        32\n",
       "text_block_1/conv_block_1/filters_0_1                     32        32\n",
       "text_block_1/conv_block_1/filters_1_0                     32        32\n",
       "text_block_1/conv_block_1/filters_1_1                     32        32\n",
       "text_block_1/spatial_reduction_1/reduction_type      flatten   flatten\n",
       "text_block_1/dense_block_1/use_batchnorm               False     False\n",
       "text_block_1/dense_block_1/num_layers                      2         2\n",
       "text_block_1/dense_block_1/units_0                        32        32\n",
       "text_block_1/dense_block_1/dropout                         0         0\n",
       "text_block_1/dense_block_1/units_1                        32        32\n",
       "regression_head_1/dropout                                  0         0\n",
       "optimizer                                               adam      adam\n",
       "learning_rate                                          0.001     0.001\n",
       "score                                               0.178598  0.185031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 64, 128)           640128    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 62, 32)            12320     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 60, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 28, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 26, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                13344     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 676,193\n",
      "Trainable params: 676,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
    "\n",
    "reg = ak.TextRegressor(overwrite=True, max_trials=2)\n",
    "# Feed the tensorflow Dataset to the regressor.\n",
    "reg.fit(train_set, epochs=2)\n",
    "# Predict with the best model.\n",
    "predicted_y = reg.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(reg.evaluate(test_set))\n",
    "\n",
    "# structure of the model\n",
    "display(hyper_table(path='text_regressor'))\n",
    "model = reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Reference\n",
    "[TextRegressor](/text_regressor),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[TextBlock](/block/#textblock-class),\n",
    "[TextToInteSequence](/block/#texttointsequence-class),\n",
    "[Embedding](/block/#embedding-class),\n",
    "[TextToNgramVector](/block/#texttongramvector-class),\n",
    "[ConvBlock](/block/#convblock-class),\n",
    "[TextInput](/node/#textinput-class),\n",
    "[RegressionHead](/block/#regressionhead-class).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_regression",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
