{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#!pip3 install autokeras\n",
    "#!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import autokeras as ak\n",
    "\n",
    "import plotly.express as px\n",
    "import copy \n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.datasets import make_classification\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_roc(y, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "\n",
    "    fig = px.area(\n",
    "        x=fpr, y=tpr,\n",
    "        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "        labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.show()\n",
    "    \n",
    "def plot_pr_curve(y, y_score):    \n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_score)\n",
    "\n",
    "    fig = px.area(\n",
    "        x=recall, y=precision,\n",
    "        title=f'Precision-Recall Curve (AUC={auc(recall, precision):.4f})',\n",
    "        labels=dict(x='Recall', y='Precision'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0\n",
    "    )\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.show()    \n",
    "    \n",
    "def plot_roc_train_test(y_train, y_score_train, y_test, y_score_test):\n",
    "    fig = go.Figure()\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{Y_Names[i]} ROC (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def plot_pr_train_test(y_train, y_score_train, y_test, y_score_test):\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    \n",
    "    # subplot for ROC curve\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{Y_Names[i]} ROC (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'),row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"True Positive Rate\", row=1, col=1)\n",
    "    \n",
    "    # subplot for PR curve\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0, \n",
    "        row=1,col=2\n",
    "    )\n",
    "    Y_Scores = [y_score_train, y_score_test]\n",
    "    Y_Obs = [y_train, y_test]\n",
    "    Y_Names = [\"Train\", \"Test\"]\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_score = average_precision_score(y_true, y_score)\n",
    "    \n",
    "        name = f\"{Y_Names[i]} PR (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=recall, y=precision, name=name, mode='lines'),row=1,col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Recall\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Precision\", row=1, col=2)\n",
    "    fig.update_layout(\n",
    "        title=\"ROC & Precision-Recall Curves\",\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=1000, height=500\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def hyper_table(path='structured_data_classifier'):\n",
    "    trial_json = os.popen('ls ./{}/trial_*/trial.json'.format(path)).read().split('\\n')[:-1]\n",
    "    DATA = []\n",
    "    for file in trial_json:\n",
    "        with open(file) as f: \n",
    "            DATA.append(json.load(f))\n",
    "    for k in range(len(DATA)):\n",
    "        DATA[k]['hyperparameters']['values']['score'] = DATA[k]['score']\n",
    "    hyper_df = pd.concat([pd.DataFrame.from_dict(data['hyperparameters']['values'], orient='index') for data in DATA], axis=1)\n",
    "    hyper_df.columns = [\"trial#{}\".format(k+1) for k in range(len(DATA))]\n",
    "    return(hyper_df)\n",
    "\n",
    "def predic_error_analysis(x_train, y_train, y_score_train, x_test, y_test, y_score):\n",
    "    df1 = copy.deepcopy(x_train)\n",
    "    df1['obs'] = y_train\n",
    "    df1['predict'] = y_score_train\n",
    "    df1['data'] = 'Train'\n",
    "    #display(df1)\n",
    "    df2 = copy.deepcopy(x_test)\n",
    "    df2['obs'] = y_test\n",
    "    df2['predict'] = y_score\n",
    "    df2['data'] = 'Test'\n",
    "    #display(df2)\n",
    "    df3 = pd.concat([df1,df2])\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df3, x='obs', y='predict',\n",
    "        marginal_x='histogram', marginal_y='histogram',\n",
    "        color='data', trendline='ols'\n",
    "    )\n",
    "    fig.update_traces(histnorm='probability', selector={'type':'histogram'})\n",
    "    fig.add_shape(\n",
    "        type=\"line\", line=dict(dash='dash'),\n",
    "        x0=df3['obs'].min(), y0=df3['obs'].min(),\n",
    "        x1=df3['obs'].max(), y1=df3['obs'].max()\n",
    "    )\n",
    "    fig.update_layout(title=\"Prediction Error Analysis\", \n",
    "                      yaxis=dict(range=[df3['obs'].min(), df3['obs'].max()]),\n",
    "                      xaxis=dict(range=[df3['obs'].min(), df3['obs'].max()]),\n",
    "                      width=1000, height=1000)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "# ROC PR curves for multi-class\n",
    "def plot_pr_multi_class(y_train, y_score_train, y_test, y_score):\n",
    "\n",
    "    y_class = np.unique(y_train)\n",
    "    class_dict_test = {}\n",
    "    for c in y_class:\n",
    "        score = [s[c] for s in y_score_test]\n",
    "        obs = y_test == c\n",
    "        class_dict_test[c] = {'obs': obs, 'score': score}\n",
    "\n",
    "    class_dict_train = {}\n",
    "    for c in y_class:\n",
    "        score = [s[c] for s in y_score_train]\n",
    "        obs = y_train == c\n",
    "        class_dict_train[c] = {'obs': obs, 'score': score}\n",
    "\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=2)\n",
    "    \n",
    "    # subplot for ROC curve: train data\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1,\n",
    "        row=1, col=1)\n",
    "    \n",
    "    Y_Scores = [class_dict_train[c]['score'] for c in class_dict_train]\n",
    "    Y_Obs = [class_dict_train[c]['obs'] for c in class_dict_train]\n",
    "    Y_Names = y_class\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"class {Y_Names[i]} ROC: Train (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'),row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"True Positive Rate (Train)\", row=1, col=1)\n",
    "\n",
    "    # subplot for ROC curve: train data\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1,\n",
    "        row=1, col=2)\n",
    "    \n",
    "    Y_Scores = [class_dict_test[c]['score'] for c in class_dict_test]\n",
    "    Y_Obs = [class_dict_test[c]['obs'] for c in class_dict_test]\n",
    "    Y_Names = y_class\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"class {Y_Names[i]} ROC: Test (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'),row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"False Positive Rate\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"True Positive Rate (Test)\", row=1, col=2)\n",
    "\n",
    "    # subplot for PR curve: train data\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0, \n",
    "        row=2,col=1)\n",
    "    Y_Scores = [class_dict_train[c]['score'] for c in class_dict_train]\n",
    "    Y_Obs = [class_dict_train[c]['obs'] for c in class_dict_train]\n",
    "    Y_Names = y_class\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_score = average_precision_score(y_true, y_score)\n",
    "    \n",
    "        name = f\"class {Y_Names[i]} PR Train (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=recall, y=precision, name=name, mode='lines'),row=2,col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Recall\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Precision (Train)\", row=2, col=1)\n",
    "\n",
    "    # subplot for PR curve: test data\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0, \n",
    "        row=2,col=2)\n",
    "    Y_Scores = [class_dict_test[c]['score'] for c in class_dict_test]\n",
    "    Y_Obs = [class_dict_test[c]['obs'] for c in class_dict_test]\n",
    "    Y_Names = y_class\n",
    "    for i in range(len(Y_Scores)):\n",
    "        y_true = Y_Obs[i]\n",
    "        y_score = Y_Scores[i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_score = average_precision_score(y_true, y_score)\n",
    "    \n",
    "        name = f\"class {Y_Names[i]} PR Test (AUC={auc_score:.4f})\"\n",
    "        fig.add_trace(go.Scatter(x=recall, y=precision, name=name, mode='lines'),row=2,col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Recall\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Precision (Test)\", row=2, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ROC & Precision-Recall Curves\",\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=1200, height=1000)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A Simple Example\n",
    "The first step is to prepare your data. Here we use the MNIST dataset as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num = 20\n",
    "k=np.random.randint(len(y_train))\n",
    "images = x_train[k:(k+num)]\n",
    "labels = y_train[k:(k+num)]\n",
    "num_row = 2\n",
    "num_col = 10\n",
    "# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title('Label: {}'.format(labels[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import plotly.express as px\n",
    "df = pd.DataFrame(y_train, columns=['label'])\n",
    "fig = px.histogram(df, x='label', nbins=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The second step is to run the ImageClassifier.\n",
    "It is recommended have more trials for more complicated datasets.\n",
    "This is just a quick demo of MNIST, so we set max_trials to 1.\n",
    "For the same reason, we set epochs to 10.\n",
    "You can also leave the epochs unspecified for an adaptive number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
    "\n",
    "# Feed the image classifier with training data. That's it!\n",
    "clf.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)\n",
    "\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text"
   },
   "outputs": [],
   "source": [
    "# performance of the model\n",
    "display(hyper_table(path='image_classifier'))\n",
    "\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "\n",
    "y_score_test = model.predict(x_test)\n",
    "y_score_train = model.predict(x_train)\n",
    "\n",
    "plot_pr_multi_class(y_train, y_score_train, y_test, y_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Validation Data\n",
    "By default, AutoKeras use the last 20% of training data as validation data. As\n",
    "shown in the example below, you can use validation_split to specify the\n",
    "percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You can also use your own validation set instead of splitting it from the\n",
    "training data with validation_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "split = 50000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Customized Search Space\n",
    "For advanced users, you may customize your search space by using __AutoModel__\n",
    "instead of ImageClassifier. You can configure the ImageBlock for some\n",
    "high-level configurations, e.g., block_type for the type of neural network to\n",
    "search, normalize for whether to do data normalization, augment for whether to\n",
    "do data augmentation. You can also do not specify these arguments, which would\n",
    "leave the different choices to be tuned automatically. See the following\n",
    "example for detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    # Only search ResNet architectures.\n",
    "    block_type=\"resnet\",\n",
    "    # Normalize the dataset.\n",
    "    normalize=True,\n",
    "    # Do not do data augmentation.\n",
    "    augment=False,\n",
    ")(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# performance of the model\n",
    "display(hyper_table(path='auto_model'))\n",
    "\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "\n",
    "y_score_test = model.predict(x_test)\n",
    "y_score_train = model.predict(x_train)\n",
    "\n",
    "plot_pr_multi_class(y_train, y_score_train, y_test, y_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The usage of AutoModel is similar to the functional API of Keras. Basically, you are\n",
    "building a graph, whose edges are blocks and the nodes are intermediate outputs of\n",
    "blocks. To add an edge from input_node to output_node with output_node =\n",
    "ak.[some_block]([block_args])(input_node).\n",
    "\n",
    "You can even also use more fine grained blocks to customize the search space even\n",
    "further. See the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
    "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "# performance of the model\n",
    "display(hyper_table(path='auto_model'))\n",
    "\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "\n",
    "y_score_test = model.predict(x_test)\n",
    "y_score_train = model.predict(x_train)\n",
    "\n",
    "plot_pr_multi_class(y_train, y_score_train, y_test, y_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data Format\n",
    "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
    "\n",
    "For the image, it accepts data formats both with and without the channel\n",
    "dimension. The images in the MNIST dataset do not have the channel dimension.\n",
    "Each image is a matrix with shape (28, 28). AutoKeras also accepts images of\n",
    "three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28,\n",
    "28, 1).\n",
    "\n",
    "For the classification labels, AutoKeras accepts both plain labels, i.e.\n",
    "strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and\n",
    "1s.\n",
    "\n",
    "So if you prepare your data in the following way, the ImageClassifier should\n",
    "still work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the images to have the channel dimension.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "# One-hot encode the labels.\n",
    "eye = np.eye(10)\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28, 1)\n",
    "print(y_train.shape)  # (60000, 10)\n",
    "print(y_train[:3])\n",
    "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We also support using tf.data.Dataset format for the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,)))\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,)))\n",
    "\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=1)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# performance of the model\n",
    "display(hyper_table(path='image_classifier'))\n",
    "\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "\n",
    "y_score_test = model.predict(x_test)\n",
    "y_score_train = model.predict(x_train)\n",
    "\n",
    "plot_pr_multi_class([np.argmax(y) for y in y_train], y_score_train, [np.argmax(y) for y in y_test], y_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Reference\n",
    "[ImageClassifier](/image_classifier),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[ImageBlock](/block/#imageblock-class),\n",
    "[Normalization](/block/#normalization-class),\n",
    "[ImageAugmentation](/block/#image-augmentation-class),\n",
    "[ResNetBlock](/block/#resnetblock-class),\n",
    "[ImageInput](/node/#imageinput-class),\n",
    "[ClassificationHead](/block/#classificationhead-class).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
